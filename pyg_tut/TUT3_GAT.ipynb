{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrDvgzJxFjEHd9lWbNwlPY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nostal1ga/8959prgram_prepare/blob/main/pyg_tut/TUT3_GAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9hWm3LPq5L14"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Structure"
      ],
      "metadata": {
        "id": "Rdn9_89c5jC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Base case\n",
        "class GATLayer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GATLayer, self).__init__()#initialize the class, call \"super\" specifying your aggregation\n",
        "\n",
        "  def forward(self, input, adj):\n",
        "    print(\" \")"
      ],
      "metadata": {
        "id": "2-GXlxCP5lww"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_features = 5\n",
        "out_features = 2\n",
        "nb_nodes = 3\n",
        "\n",
        "W = nn.Parameter(torch.zeros(size=(in_features,out_features)))\n",
        "nn.init.xavier_uniform_(W.data,gain=1.414)\n",
        "input = torch.rand(nb_nodes,in_features)\n",
        "\n",
        "h = torch.mm(input,W)\n",
        "N = h.size()[0]\n",
        "\n",
        "print(h.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqH9g8se5xcz",
        "outputId": "93707505-231a-4353-8f9e-5744ee46c24c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = nn.Parameter(torch.zeros(size=(2*out_features,1)))\n",
        "nn.init.xavier_uniform_(a.data,gain = 1.414)\n",
        "print(a.shape)\n",
        "\n",
        "leakyrelu = nn.LeakyReLU(0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqZaSpYl7fv0",
        "outputId": "a69133e6-a07f-440d-ddad-60792935ce16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_input = torch.cat([h.repeat(1,N).view(N*N,-1), h.repeat(N,1)], dim=1).view(N,-1,2*out_features)"
      ],
      "metadata": {
        "id": "9764lyy49OUY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e = leakyrelu(torch.matmul(a_input,a).squeeze(2))"
      ],
      "metadata": {
        "id": "q1b_e4jg_F6D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a_input.shape, a.shape)\n",
        "print(\"\")\n",
        "print(torch.matmul(a_input,a).shape)\n",
        "print(\"\")\n",
        "print(torch.matmul(a_input,a).squeeze(2).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "330pvkfx-nHI",
        "outputId": "660e8bc7-18a5-4046-f30f-cc04887502fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 3, 4]) torch.Size([4, 1])\n",
            "\n",
            "torch.Size([3, 3, 1])\n",
            "\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masked Attention"
      ],
      "metadata": {
        "id": "U9pGX3qAB90e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked Attention\n",
        "adj = torch.randint(2,(3,3))\n",
        "zero_vec = -9e15*torch.ones_like(e)\n",
        "print(zero_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8bOGDTeA2LT",
        "outputId": "bc32e4e4-e36c-4f1a-e1f6-90fb84a0922d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention = torch.where(adj>0, e, zero_vec)\n",
        "print(adj, \"\\n\", e, \"\\n\", zero_vec)\n",
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRXrGPngCOdu",
        "outputId": "b3fc2cba-bb7c-46d1-f50a-16fa2c4d8a1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 0, 1],\n",
            "        [0, 0, 0],\n",
            "        [0, 1, 1]]) \n",
            " tensor([[-0.2220, -0.0950,  0.2007],\n",
            "        [-0.3181, -0.1911, -0.0559],\n",
            "        [-0.4623, -0.3354, -0.2002]], grad_fn=<LeakyReluBackward0>) \n",
            " tensor([[-9.0000e+15, -9.0000e+15, -9.0000e+15],\n",
            "        [-9.0000e+15, -9.0000e+15, -9.0000e+15],\n",
            "        [-9.0000e+15, -9.0000e+15, -9.0000e+15]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.2200e-01, -9.0000e+15,  2.0066e-01],\n",
              "        [-9.0000e+15, -9.0000e+15, -9.0000e+15],\n",
              "        [-9.0000e+15, -3.3538e-01, -2.0021e-01]], grad_fn=<WhereBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention = F.softmax(attention, dim =1)\n",
        "h_prime = torch.matmul(attention,h)"
      ],
      "metadata": {
        "id": "7p-0tobMDY_d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFZOTpQwHai2",
        "outputId": "e1f37b5d-3e31-4343-e810-60fec4ee6305"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3959, 0.0000, 0.6041],\n",
              "        [0.3333, 0.3333, 0.3333],\n",
              "        [0.0000, 0.4663, 0.5337]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_prime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV1NKQNqHbXO",
        "outputId": "dcde4612-bfd4-4430-9f25-bdb5b1d93a16"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.4552, -1.4964],\n",
              "        [ 2.5126, -1.3958],\n",
              "        [ 2.2673, -1.4275]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a layer"
      ],
      "metadata": {
        "id": "2Y87XTyWIkG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GATLayer(nn.Module):#full step to initlialize the layer\n",
        "  def __init__(self, in_features, out_features, dropout,alpha, concat=True):\n",
        "    super(GATLayer,self).__init__()\n",
        "    self.dropout = dropout\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.alpha = alpha\n",
        "    self.concat = concat\n",
        "\n",
        "    #Xavier Initialization of weights\n",
        "    self.W = nn.Parameter(torch.zeros(size=(in_features,out_features)))\n",
        "    nn.init.xavier_uniform_(self.W.data, gain =1.414)\n",
        "\n",
        "    self.a = nn.Paramter(torch.zeros(size=(2*out_features,1)))\n",
        "    nn.init.xavier_uniform_(self.a.data, gain=1.414)"
      ],
      "metadata": {
        "id": "UJNBo3aLIjUf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_74teZz4Jp0k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}